{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e2fb6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPython \u001b[36m3.10.17\u001b[39m\n",
      "Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
      "Activate with: \u001b[32msource .venv/bin/activate\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "!uv venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdc8eeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.9 environment at: /Users/ElliotPhua/miniconda3\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 5ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!source .venv/bin/activate\n",
    "!uv pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c092287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "corpus = \"\" # corpus\n",
    "\n",
    "def preprocess_corpus(corpus: str) -> tuple[dict[str, int], dict[int, str], np.ndarray]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        corpus (str)\n",
    "    Returns:\n",
    "        dict[str, int]: ind_dict[k=word, v=index]\n",
    "        dict[int, str]: str_dict[k=index, v=word]\n",
    "        np.ndarray: an ndarray of word indices corresponding to the input corpus (ground truth)\n",
    "    \"\"\"\n",
    "    tokens = re.findall(r\"\\b\\w+\\b\", corpus)\n",
    "    ind_dict = {} # k=word, v=ind\n",
    "    str_dict = {} # k=ind, v=word\n",
    "    count = 0\n",
    "    for word in tokens:\n",
    "        if word not in ind_dict:\n",
    "            ind_dict[word] = count\n",
    "            str_dict[count] = word\n",
    "            count += 1\n",
    "    \n",
    "    data_ind = np.array([ind_dict[w] for w in tokens])\n",
    "    \n",
    "    return ind_dict, str_dict, data_ind\n",
    "\n",
    "def make_sequences(data_ind: np.ndarray, seq_len:int=5) -> tuple[np.ndarray, np.ndarray]:\n",
    "    X = np.array([data_ind[i:i+seq_len] for i in range(len(data_ind) - seq_len)])\n",
    "    Y = np.array([data_ind[i+seq_len] for i in range(len(data_ind) - seq_len)])\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42a280f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recurrent Neural Network\n",
    "import numpy as np\n",
    "\n",
    "def get_word_embedding(x_t:str, ind_dt:dict[str, int], w_e:np.ndarray) -> np.ndarray:\n",
    "    '''\n",
    "    Convert word into vector embedding.\n",
    "    Args:\n",
    "        x_t (str): The target word.\n",
    "        ind_dt (dict): Dictionary of vocab, where key is the word and value is its row index in the weight embedding w_e.\n",
    "        w_e (np.ndarray): A 2d weight embedding of shape |V| x d, where V is the number of words in vocab and d is the embedding space.\n",
    "    Returns:\n",
    "        np.ndarray: Returns a np.array of shape 1 x d, denoting the vector embedding for the target word.\n",
    "    '''\n",
    "    row_ind = ind_dt[x_t]\n",
    "    return w_e[row_ind, :]\n",
    "\n",
    "def get_h_t(e_t:np.ndarray, prev_h:np.ndarray, w_hh:np.ndarray, w_xh:np.ndarray, b_h:np.ndarray) -> np.ndarray:\n",
    "    '''\n",
    "    h_t <- f(x_t, h_t-1)\n",
    "    Get current state memory, dependent on current word embedding e_t and state memory at previous time step prev_h, and using the weight embedding w_hh.\n",
    "    Args:\n",
    "        e_t (np.ndarray): The vector embedding for target word with shape 1 x d, where d is the embedding space.\n",
    "        prev_h (np.ndarray): The state memory at previous time step t-1, with shape H x 1\n",
    "        w_hh (np.ndarray): weight embedding for state memory, shape H x H\n",
    "        w_xh (np.ndarray): weight embedding to transform target word embedding into space of state memory embedding, shape H x d\n",
    "        b_h (np.ndarray): bias with shape H x 1\n",
    "    Returns:\n",
    "        np.ndarray: the current state memory h_t, shape H x 1\n",
    "    '''\n",
    "    h_t = np.tanh(w_xh.T@e_t + w_hh.T@prev_h + b_h) # tanh prevents exploding gradients and gives hidden state non-linearity\n",
    "    return h_t\n",
    "\n",
    "def predict_z_t(h_t:np.ndarray, w_hy:np.ndarray, b_y:np.ndarray) -> np.ndarray:\n",
    "    '''\n",
    "    Get the output raw score for all candidate output words\n",
    "    Args:\n",
    "        h_t (np.ndarray): the current state memory embedding, shape H x 1\n",
    "        w_hy (np.ndarray): the output score embedding, shape H x |v|\n",
    "        b_y (np.ndarray): the bias for output score, shape |v| x 1\n",
    "    Returns:\n",
    "        np.ndarray: the raw score vector for all candidate words, shape |v| x 1\n",
    "    '''\n",
    "    return w_hy.T@h_t + b_y\n",
    "\n",
    "def softmax(z_t: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    softmax(z_i) = exp(z_i - C)/sum[j in T](exp(z_j - C)), numerical stability\n",
    "    \"\"\"\n",
    "    exp_z = np.exp(z_t - np.max(z_t))\n",
    "    return exp_z/np.sum(exp_z, axis=1, keepdims=True)\n",
    "    \n",
    "def get_most_likely_output_word(p_t:np.ndarray, str_dict: dict[int, str]) -> str:\n",
    "    index_of_max_p = np.argmax(p_t)\n",
    "    return str_dict[int(index_of_max_p)] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bece9e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f14b78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5406f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backpropagation through time (BPTT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d100a3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.9 environment at: /Users/ElliotPhua/miniconda3\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m3 packages\u001b[0m \u001b[2min 5ms\u001b[0m\u001b[0m\n",
      "\u001b[2mUsing Python 3.12.9 environment at: /Users/ElliotPhua/miniconda3\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m2 packages\u001b[0m \u001b[2min 6ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu\n",
    "!uv pip install scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c37fdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# Using pytorch\n",
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print(x)\n",
    "else: print(\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86b25201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1   2   3   4]\n",
      " [  1   2   3   4   5]\n",
      " [  2   3   4   5   6]\n",
      " ...\n",
      " [275 197 254 196 275]\n",
      " [197 254 196 275 197]\n",
      " [254 196 275 197 446]] [  5   6   7 ... 197 446 492]\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "fp = \"data/text8\"\n",
    "\n",
    "with open(fp, 'r') as f:\n",
    "    corpus = f.read().lower()\n",
    "\n",
    "ind_dict, str_dict, data_indices = preprocess_corpus(corpus)\n",
    "\n",
    "X, Y = make_sequences(data_indices, seq_len=5)\n",
    "print(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f2552f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e66435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  285     5 15706   149 58437]\n",
      " [  196   275   197   197 31467]\n",
      " [   26    15   604   592   118]\n",
      " ...\n",
      " [   15  9813   361  4519   315]\n",
      " [  459  4106   106  2449   218]\n",
      " [77935  9473  5816    26 77935]] [  2222    167    457 ...      3 206857  31521]\n"
     ]
    }
   ],
   "source": [
    "# initialise input embedding, w_xh, w_hh, w_hy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4b9744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
